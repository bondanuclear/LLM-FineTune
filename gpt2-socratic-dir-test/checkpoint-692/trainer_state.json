{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 692,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014450867052023121,
      "grad_norm": 0.6338176727294922,
      "learning_rate": 3.5971223021582732e-06,
      "loss": 3.7833,
      "step": 10
    },
    {
      "epoch": 0.028901734104046242,
      "grad_norm": 0.9328519701957703,
      "learning_rate": 7.1942446043165465e-06,
      "loss": 3.7708,
      "step": 20
    },
    {
      "epoch": 0.04335260115606936,
      "grad_norm": 0.7859657406806946,
      "learning_rate": 1.0791366906474821e-05,
      "loss": 3.7893,
      "step": 30
    },
    {
      "epoch": 0.057803468208092484,
      "grad_norm": 0.8425351977348328,
      "learning_rate": 1.4388489208633093e-05,
      "loss": 3.7633,
      "step": 40
    },
    {
      "epoch": 0.07225433526011561,
      "grad_norm": 0.8633155822753906,
      "learning_rate": 1.7985611510791367e-05,
      "loss": 3.6982,
      "step": 50
    },
    {
      "epoch": 0.08670520231213873,
      "grad_norm": 0.9733292460441589,
      "learning_rate": 2.1582733812949642e-05,
      "loss": 3.8193,
      "step": 60
    },
    {
      "epoch": 0.10115606936416185,
      "grad_norm": 1.0403269529342651,
      "learning_rate": 2.5179856115107914e-05,
      "loss": 3.765,
      "step": 70
    },
    {
      "epoch": 0.11560693641618497,
      "grad_norm": 1.0769615173339844,
      "learning_rate": 2.8776978417266186e-05,
      "loss": 3.6991,
      "step": 80
    },
    {
      "epoch": 0.13005780346820808,
      "grad_norm": 1.3194289207458496,
      "learning_rate": 3.237410071942446e-05,
      "loss": 3.6828,
      "step": 90
    },
    {
      "epoch": 0.14450867052023122,
      "grad_norm": 1.6155569553375244,
      "learning_rate": 3.597122302158273e-05,
      "loss": 3.6552,
      "step": 100
    },
    {
      "epoch": 0.15895953757225434,
      "grad_norm": 1.0198220014572144,
      "learning_rate": 3.956834532374101e-05,
      "loss": 3.4803,
      "step": 110
    },
    {
      "epoch": 0.17341040462427745,
      "grad_norm": 1.3547694683074951,
      "learning_rate": 4.3165467625899284e-05,
      "loss": 3.5782,
      "step": 120
    },
    {
      "epoch": 0.18786127167630057,
      "grad_norm": 1.3499767780303955,
      "learning_rate": 4.676258992805755e-05,
      "loss": 3.4373,
      "step": 130
    },
    {
      "epoch": 0.2023121387283237,
      "grad_norm": 1.317399263381958,
      "learning_rate": 4.995983935742972e-05,
      "loss": 3.4704,
      "step": 140
    },
    {
      "epoch": 0.21676300578034682,
      "grad_norm": 1.134781837463379,
      "learning_rate": 4.955823293172691e-05,
      "loss": 3.4057,
      "step": 150
    },
    {
      "epoch": 0.23121387283236994,
      "grad_norm": 0.9982414841651917,
      "learning_rate": 4.9156626506024104e-05,
      "loss": 3.3473,
      "step": 160
    },
    {
      "epoch": 0.24566473988439305,
      "grad_norm": 0.9833696484565735,
      "learning_rate": 4.875502008032129e-05,
      "loss": 3.2728,
      "step": 170
    },
    {
      "epoch": 0.26011560693641617,
      "grad_norm": 1.047238826751709,
      "learning_rate": 4.8353413654618476e-05,
      "loss": 3.3043,
      "step": 180
    },
    {
      "epoch": 0.2745664739884393,
      "grad_norm": 0.9287770986557007,
      "learning_rate": 4.7951807228915665e-05,
      "loss": 3.2344,
      "step": 190
    },
    {
      "epoch": 0.28901734104046245,
      "grad_norm": 0.8354200124740601,
      "learning_rate": 4.7550200803212854e-05,
      "loss": 3.194,
      "step": 200
    },
    {
      "epoch": 0.30346820809248554,
      "grad_norm": 0.8808484673500061,
      "learning_rate": 4.714859437751004e-05,
      "loss": 3.1977,
      "step": 210
    },
    {
      "epoch": 0.3179190751445087,
      "grad_norm": 0.7792506217956543,
      "learning_rate": 4.674698795180723e-05,
      "loss": 3.0889,
      "step": 220
    },
    {
      "epoch": 0.33236994219653176,
      "grad_norm": 0.7389611005783081,
      "learning_rate": 4.634538152610442e-05,
      "loss": 3.1399,
      "step": 230
    },
    {
      "epoch": 0.3468208092485549,
      "grad_norm": 0.871417760848999,
      "learning_rate": 4.594377510040161e-05,
      "loss": 3.0631,
      "step": 240
    },
    {
      "epoch": 0.36127167630057805,
      "grad_norm": 0.8647934198379517,
      "learning_rate": 4.55421686746988e-05,
      "loss": 3.0262,
      "step": 250
    },
    {
      "epoch": 0.37572254335260113,
      "grad_norm": 0.8375223875045776,
      "learning_rate": 4.514056224899599e-05,
      "loss": 3.1178,
      "step": 260
    },
    {
      "epoch": 0.3901734104046243,
      "grad_norm": 0.8261134624481201,
      "learning_rate": 4.473895582329318e-05,
      "loss": 3.0482,
      "step": 270
    },
    {
      "epoch": 0.4046242774566474,
      "grad_norm": 0.8245840668678284,
      "learning_rate": 4.433734939759036e-05,
      "loss": 2.9929,
      "step": 280
    },
    {
      "epoch": 0.4190751445086705,
      "grad_norm": 0.873359203338623,
      "learning_rate": 4.393574297188755e-05,
      "loss": 2.9308,
      "step": 290
    },
    {
      "epoch": 0.43352601156069365,
      "grad_norm": 0.9003682732582092,
      "learning_rate": 4.353413654618474e-05,
      "loss": 3.0255,
      "step": 300
    },
    {
      "epoch": 0.4479768786127168,
      "grad_norm": 0.9605580568313599,
      "learning_rate": 4.313253012048193e-05,
      "loss": 3.0321,
      "step": 310
    },
    {
      "epoch": 0.4624277456647399,
      "grad_norm": 0.9550971984863281,
      "learning_rate": 4.273092369477912e-05,
      "loss": 2.9538,
      "step": 320
    },
    {
      "epoch": 0.476878612716763,
      "grad_norm": 0.9975482225418091,
      "learning_rate": 4.232931726907631e-05,
      "loss": 2.8506,
      "step": 330
    },
    {
      "epoch": 0.4913294797687861,
      "grad_norm": 0.930985152721405,
      "learning_rate": 4.1927710843373496e-05,
      "loss": 2.9498,
      "step": 340
    },
    {
      "epoch": 0.5057803468208093,
      "grad_norm": 0.9944967031478882,
      "learning_rate": 4.1526104417670686e-05,
      "loss": 2.9165,
      "step": 350
    },
    {
      "epoch": 0.5202312138728323,
      "grad_norm": 1.0651510953903198,
      "learning_rate": 4.1124497991967875e-05,
      "loss": 2.8466,
      "step": 360
    },
    {
      "epoch": 0.5346820809248555,
      "grad_norm": 1.0028268098831177,
      "learning_rate": 4.0722891566265064e-05,
      "loss": 2.9349,
      "step": 370
    },
    {
      "epoch": 0.5491329479768786,
      "grad_norm": 0.9597352147102356,
      "learning_rate": 4.0321285140562246e-05,
      "loss": 2.8264,
      "step": 380
    },
    {
      "epoch": 0.5635838150289018,
      "grad_norm": 0.9460840821266174,
      "learning_rate": 3.9919678714859436e-05,
      "loss": 2.881,
      "step": 390
    },
    {
      "epoch": 0.5780346820809249,
      "grad_norm": 1.0761054754257202,
      "learning_rate": 3.9518072289156625e-05,
      "loss": 2.9015,
      "step": 400
    },
    {
      "epoch": 0.5924855491329479,
      "grad_norm": 1.058117389678955,
      "learning_rate": 3.9116465863453814e-05,
      "loss": 2.8659,
      "step": 410
    },
    {
      "epoch": 0.6069364161849711,
      "grad_norm": 1.1236591339111328,
      "learning_rate": 3.8714859437751e-05,
      "loss": 2.8038,
      "step": 420
    },
    {
      "epoch": 0.6213872832369942,
      "grad_norm": 1.0592775344848633,
      "learning_rate": 3.831325301204819e-05,
      "loss": 2.8727,
      "step": 430
    },
    {
      "epoch": 0.6358381502890174,
      "grad_norm": 1.061248540878296,
      "learning_rate": 3.791164658634538e-05,
      "loss": 2.7977,
      "step": 440
    },
    {
      "epoch": 0.6502890173410405,
      "grad_norm": 1.2862145900726318,
      "learning_rate": 3.751004016064257e-05,
      "loss": 2.8486,
      "step": 450
    },
    {
      "epoch": 0.6647398843930635,
      "grad_norm": 1.2827205657958984,
      "learning_rate": 3.710843373493976e-05,
      "loss": 2.8321,
      "step": 460
    },
    {
      "epoch": 0.6791907514450867,
      "grad_norm": 1.0595139265060425,
      "learning_rate": 3.670682730923695e-05,
      "loss": 2.7776,
      "step": 470
    },
    {
      "epoch": 0.6936416184971098,
      "grad_norm": 1.0735368728637695,
      "learning_rate": 3.630522088353414e-05,
      "loss": 2.7663,
      "step": 480
    },
    {
      "epoch": 0.708092485549133,
      "grad_norm": 0.9604960083961487,
      "learning_rate": 3.590361445783133e-05,
      "loss": 2.7274,
      "step": 490
    },
    {
      "epoch": 0.7225433526011561,
      "grad_norm": 0.9627233147621155,
      "learning_rate": 3.550200803212852e-05,
      "loss": 2.7725,
      "step": 500
    },
    {
      "epoch": 0.7369942196531792,
      "grad_norm": 1.0740562677383423,
      "learning_rate": 3.5100401606425706e-05,
      "loss": 2.772,
      "step": 510
    },
    {
      "epoch": 0.7514450867052023,
      "grad_norm": 1.0622196197509766,
      "learning_rate": 3.4698795180722896e-05,
      "loss": 2.6842,
      "step": 520
    },
    {
      "epoch": 0.7658959537572254,
      "grad_norm": 1.0736061334609985,
      "learning_rate": 3.4297188755020085e-05,
      "loss": 2.7593,
      "step": 530
    },
    {
      "epoch": 0.7803468208092486,
      "grad_norm": 1.1282665729522705,
      "learning_rate": 3.3895582329317274e-05,
      "loss": 2.7507,
      "step": 540
    },
    {
      "epoch": 0.7947976878612717,
      "grad_norm": 1.129516839981079,
      "learning_rate": 3.349397590361446e-05,
      "loss": 2.8157,
      "step": 550
    },
    {
      "epoch": 0.8092485549132948,
      "grad_norm": 1.1708241701126099,
      "learning_rate": 3.309236947791165e-05,
      "loss": 2.7158,
      "step": 560
    },
    {
      "epoch": 0.8236994219653179,
      "grad_norm": 1.1060807704925537,
      "learning_rate": 3.269076305220884e-05,
      "loss": 2.7135,
      "step": 570
    },
    {
      "epoch": 0.838150289017341,
      "grad_norm": 1.1296305656433105,
      "learning_rate": 3.2289156626506024e-05,
      "loss": 2.7814,
      "step": 580
    },
    {
      "epoch": 0.8526011560693642,
      "grad_norm": 1.1117331981658936,
      "learning_rate": 3.1887550200803213e-05,
      "loss": 2.7234,
      "step": 590
    },
    {
      "epoch": 0.8670520231213873,
      "grad_norm": 1.099324107170105,
      "learning_rate": 3.14859437751004e-05,
      "loss": 2.7255,
      "step": 600
    },
    {
      "epoch": 0.8815028901734104,
      "grad_norm": 1.1216002702713013,
      "learning_rate": 3.108433734939759e-05,
      "loss": 2.7118,
      "step": 610
    },
    {
      "epoch": 0.8959537572254336,
      "grad_norm": 1.0290249586105347,
      "learning_rate": 3.068273092369478e-05,
      "loss": 2.6623,
      "step": 620
    },
    {
      "epoch": 0.9104046242774566,
      "grad_norm": 1.1533362865447998,
      "learning_rate": 3.028112449799197e-05,
      "loss": 2.6703,
      "step": 630
    },
    {
      "epoch": 0.9248554913294798,
      "grad_norm": 1.0425360202789307,
      "learning_rate": 2.987951807228916e-05,
      "loss": 2.6676,
      "step": 640
    },
    {
      "epoch": 0.9393063583815029,
      "grad_norm": 1.1484568119049072,
      "learning_rate": 2.947791164658635e-05,
      "loss": 2.6637,
      "step": 650
    },
    {
      "epoch": 0.953757225433526,
      "grad_norm": 1.2296143770217896,
      "learning_rate": 2.9076305220883538e-05,
      "loss": 2.6145,
      "step": 660
    },
    {
      "epoch": 0.9682080924855492,
      "grad_norm": 1.1838223934173584,
      "learning_rate": 2.8674698795180727e-05,
      "loss": 2.6583,
      "step": 670
    },
    {
      "epoch": 0.9826589595375722,
      "grad_norm": 1.3593010902404785,
      "learning_rate": 2.827309236947791e-05,
      "loss": 2.6282,
      "step": 680
    },
    {
      "epoch": 0.9971098265895953,
      "grad_norm": 1.2605606317520142,
      "learning_rate": 2.78714859437751e-05,
      "loss": 2.7071,
      "step": 690
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.487121105194092,
      "eval_runtime": 191.1788,
      "eval_samples_per_second": 5.252,
      "eval_steps_per_second": 0.659,
      "step": 692
    }
  ],
  "logging_steps": 10,
  "max_steps": 1384,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 362757463474176.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
