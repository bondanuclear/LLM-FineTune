{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 692,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.014450867052023121,
      "grad_norm": 0.4773590862751007,
      "learning_rate": 3.5971223021582732e-06,
      "loss": 3.7833,
      "step": 10
    },
    {
      "epoch": 0.028901734104046242,
      "grad_norm": 0.7151181101799011,
      "learning_rate": 7.1942446043165465e-06,
      "loss": 3.7712,
      "step": 20
    },
    {
      "epoch": 0.04335260115606936,
      "grad_norm": 0.6033282279968262,
      "learning_rate": 1.0791366906474821e-05,
      "loss": 3.7902,
      "step": 30
    },
    {
      "epoch": 0.057803468208092484,
      "grad_norm": 0.6800493001937866,
      "learning_rate": 1.4388489208633093e-05,
      "loss": 3.7653,
      "step": 40
    },
    {
      "epoch": 0.07225433526011561,
      "grad_norm": 0.7056021690368652,
      "learning_rate": 1.7985611510791367e-05,
      "loss": 3.701,
      "step": 50
    },
    {
      "epoch": 0.08670520231213873,
      "grad_norm": 0.8120033144950867,
      "learning_rate": 2.1582733812949642e-05,
      "loss": 3.8243,
      "step": 60
    },
    {
      "epoch": 0.10115606936416185,
      "grad_norm": 0.8941109776496887,
      "learning_rate": 2.5179856115107914e-05,
      "loss": 3.7716,
      "step": 70
    },
    {
      "epoch": 0.11560693641618497,
      "grad_norm": 0.9626595377922058,
      "learning_rate": 2.8776978417266186e-05,
      "loss": 3.7057,
      "step": 80
    },
    {
      "epoch": 0.13005780346820808,
      "grad_norm": 1.2160077095031738,
      "learning_rate": 3.237410071942446e-05,
      "loss": 3.6895,
      "step": 90
    },
    {
      "epoch": 0.14450867052023122,
      "grad_norm": 1.5225915908813477,
      "learning_rate": 3.597122302158273e-05,
      "loss": 3.6631,
      "step": 100
    },
    {
      "epoch": 0.15895953757225434,
      "grad_norm": 0.9782919883728027,
      "learning_rate": 3.956834532374101e-05,
      "loss": 3.4846,
      "step": 110
    },
    {
      "epoch": 0.17341040462427745,
      "grad_norm": 1.3269627094268799,
      "learning_rate": 4.3165467625899284e-05,
      "loss": 3.5845,
      "step": 120
    },
    {
      "epoch": 0.18786127167630057,
      "grad_norm": 1.3205915689468384,
      "learning_rate": 4.676258992805755e-05,
      "loss": 3.4419,
      "step": 130
    },
    {
      "epoch": 0.2023121387283237,
      "grad_norm": 1.314456820487976,
      "learning_rate": 4.995983935742972e-05,
      "loss": 3.475,
      "step": 140
    },
    {
      "epoch": 0.21676300578034682,
      "grad_norm": 1.125549077987671,
      "learning_rate": 4.955823293172691e-05,
      "loss": 3.411,
      "step": 150
    },
    {
      "epoch": 0.23121387283236994,
      "grad_norm": 0.982186496257782,
      "learning_rate": 4.9156626506024104e-05,
      "loss": 3.3526,
      "step": 160
    },
    {
      "epoch": 0.24566473988439305,
      "grad_norm": 0.9746118783950806,
      "learning_rate": 4.875502008032129e-05,
      "loss": 3.2781,
      "step": 170
    },
    {
      "epoch": 0.26011560693641617,
      "grad_norm": 1.026100516319275,
      "learning_rate": 4.8353413654618476e-05,
      "loss": 3.3099,
      "step": 180
    },
    {
      "epoch": 0.2745664739884393,
      "grad_norm": 0.9269070029258728,
      "learning_rate": 4.7951807228915665e-05,
      "loss": 3.2404,
      "step": 190
    },
    {
      "epoch": 0.28901734104046245,
      "grad_norm": 0.8253796696662903,
      "learning_rate": 4.7550200803212854e-05,
      "loss": 3.1995,
      "step": 200
    },
    {
      "epoch": 0.30346820809248554,
      "grad_norm": 0.8523250222206116,
      "learning_rate": 4.714859437751004e-05,
      "loss": 3.2033,
      "step": 210
    },
    {
      "epoch": 0.3179190751445087,
      "grad_norm": 0.7683552503585815,
      "learning_rate": 4.674698795180723e-05,
      "loss": 3.0935,
      "step": 220
    },
    {
      "epoch": 0.33236994219653176,
      "grad_norm": 0.7244157791137695,
      "learning_rate": 4.634538152610442e-05,
      "loss": 3.1444,
      "step": 230
    },
    {
      "epoch": 0.3468208092485549,
      "grad_norm": 0.8366519212722778,
      "learning_rate": 4.594377510040161e-05,
      "loss": 3.0686,
      "step": 240
    },
    {
      "epoch": 0.36127167630057805,
      "grad_norm": 0.8437788486480713,
      "learning_rate": 4.55421686746988e-05,
      "loss": 3.031,
      "step": 250
    },
    {
      "epoch": 0.37572254335260113,
      "grad_norm": 0.8275673389434814,
      "learning_rate": 4.514056224899599e-05,
      "loss": 3.1216,
      "step": 260
    },
    {
      "epoch": 0.3901734104046243,
      "grad_norm": 0.8020057678222656,
      "learning_rate": 4.473895582329318e-05,
      "loss": 3.0533,
      "step": 270
    },
    {
      "epoch": 0.4046242774566474,
      "grad_norm": 0.814189612865448,
      "learning_rate": 4.433734939759036e-05,
      "loss": 2.9959,
      "step": 280
    },
    {
      "epoch": 0.4190751445086705,
      "grad_norm": 0.8557850122451782,
      "learning_rate": 4.393574297188755e-05,
      "loss": 2.9353,
      "step": 290
    },
    {
      "epoch": 0.43352601156069365,
      "grad_norm": 0.8782809376716614,
      "learning_rate": 4.353413654618474e-05,
      "loss": 3.0285,
      "step": 300
    },
    {
      "epoch": 0.4479768786127168,
      "grad_norm": 0.9386831521987915,
      "learning_rate": 4.313253012048193e-05,
      "loss": 3.0343,
      "step": 310
    },
    {
      "epoch": 0.4624277456647399,
      "grad_norm": 0.9434203505516052,
      "learning_rate": 4.273092369477912e-05,
      "loss": 2.9556,
      "step": 320
    },
    {
      "epoch": 0.476878612716763,
      "grad_norm": 0.9923467636108398,
      "learning_rate": 4.232931726907631e-05,
      "loss": 2.8521,
      "step": 330
    },
    {
      "epoch": 0.4913294797687861,
      "grad_norm": 0.9191104769706726,
      "learning_rate": 4.1927710843373496e-05,
      "loss": 2.9503,
      "step": 340
    },
    {
      "epoch": 0.5057803468208093,
      "grad_norm": 0.9750847816467285,
      "learning_rate": 4.1526104417670686e-05,
      "loss": 2.9179,
      "step": 350
    },
    {
      "epoch": 0.5202312138728323,
      "grad_norm": 1.0308159589767456,
      "learning_rate": 4.1124497991967875e-05,
      "loss": 2.8468,
      "step": 360
    },
    {
      "epoch": 0.5346820809248555,
      "grad_norm": 1.0001957416534424,
      "learning_rate": 4.0722891566265064e-05,
      "loss": 2.9341,
      "step": 370
    },
    {
      "epoch": 0.5491329479768786,
      "grad_norm": 0.9109511971473694,
      "learning_rate": 4.0321285140562246e-05,
      "loss": 2.8258,
      "step": 380
    },
    {
      "epoch": 0.5635838150289018,
      "grad_norm": 0.9348042607307434,
      "learning_rate": 3.9919678714859436e-05,
      "loss": 2.8792,
      "step": 390
    },
    {
      "epoch": 0.5780346820809249,
      "grad_norm": 1.0832616090774536,
      "learning_rate": 3.9518072289156625e-05,
      "loss": 2.9001,
      "step": 400
    },
    {
      "epoch": 0.5924855491329479,
      "grad_norm": 1.0147678852081299,
      "learning_rate": 3.9116465863453814e-05,
      "loss": 2.8633,
      "step": 410
    },
    {
      "epoch": 0.6069364161849711,
      "grad_norm": 1.1274040937423706,
      "learning_rate": 3.8714859437751e-05,
      "loss": 2.8038,
      "step": 420
    },
    {
      "epoch": 0.6213872832369942,
      "grad_norm": 1.0238709449768066,
      "learning_rate": 3.831325301204819e-05,
      "loss": 2.8706,
      "step": 430
    },
    {
      "epoch": 0.6358381502890174,
      "grad_norm": 1.0547271966934204,
      "learning_rate": 3.791164658634538e-05,
      "loss": 2.7952,
      "step": 440
    },
    {
      "epoch": 0.6502890173410405,
      "grad_norm": 1.245968222618103,
      "learning_rate": 3.751004016064257e-05,
      "loss": 2.8471,
      "step": 450
    },
    {
      "epoch": 0.6647398843930635,
      "grad_norm": 1.252712607383728,
      "learning_rate": 3.710843373493976e-05,
      "loss": 2.8297,
      "step": 460
    },
    {
      "epoch": 0.6791907514450867,
      "grad_norm": 1.0350323915481567,
      "learning_rate": 3.670682730923695e-05,
      "loss": 2.7751,
      "step": 470
    },
    {
      "epoch": 0.6936416184971098,
      "grad_norm": 1.0472110509872437,
      "learning_rate": 3.630522088353414e-05,
      "loss": 2.7636,
      "step": 480
    },
    {
      "epoch": 0.708092485549133,
      "grad_norm": 0.9465208053588867,
      "learning_rate": 3.590361445783133e-05,
      "loss": 2.7261,
      "step": 490
    },
    {
      "epoch": 0.7225433526011561,
      "grad_norm": 0.9796590805053711,
      "learning_rate": 3.550200803212852e-05,
      "loss": 2.7711,
      "step": 500
    },
    {
      "epoch": 0.7369942196531792,
      "grad_norm": 1.0718580484390259,
      "learning_rate": 3.5100401606425706e-05,
      "loss": 2.7691,
      "step": 510
    },
    {
      "epoch": 0.7514450867052023,
      "grad_norm": 1.0348858833312988,
      "learning_rate": 3.4698795180722896e-05,
      "loss": 2.6807,
      "step": 520
    },
    {
      "epoch": 0.7658959537572254,
      "grad_norm": 1.0460807085037231,
      "learning_rate": 3.4297188755020085e-05,
      "loss": 2.7566,
      "step": 530
    },
    {
      "epoch": 0.7803468208092486,
      "grad_norm": 1.0998892784118652,
      "learning_rate": 3.3895582329317274e-05,
      "loss": 2.7472,
      "step": 540
    },
    {
      "epoch": 0.7947976878612717,
      "grad_norm": 1.1205788850784302,
      "learning_rate": 3.349397590361446e-05,
      "loss": 2.8118,
      "step": 550
    },
    {
      "epoch": 0.8092485549132948,
      "grad_norm": 1.1423025131225586,
      "learning_rate": 3.309236947791165e-05,
      "loss": 2.7124,
      "step": 560
    },
    {
      "epoch": 0.8236994219653179,
      "grad_norm": 1.0714898109436035,
      "learning_rate": 3.269076305220884e-05,
      "loss": 2.7108,
      "step": 570
    },
    {
      "epoch": 0.838150289017341,
      "grad_norm": 1.0902395248413086,
      "learning_rate": 3.2289156626506024e-05,
      "loss": 2.7792,
      "step": 580
    },
    {
      "epoch": 0.8526011560693642,
      "grad_norm": 1.0998562574386597,
      "learning_rate": 3.1887550200803213e-05,
      "loss": 2.7199,
      "step": 590
    },
    {
      "epoch": 0.8670520231213873,
      "grad_norm": 1.078199863433838,
      "learning_rate": 3.14859437751004e-05,
      "loss": 2.7217,
      "step": 600
    },
    {
      "epoch": 0.8815028901734104,
      "grad_norm": 1.1076446771621704,
      "learning_rate": 3.108433734939759e-05,
      "loss": 2.7093,
      "step": 610
    },
    {
      "epoch": 0.8959537572254336,
      "grad_norm": 1.030458927154541,
      "learning_rate": 3.068273092369478e-05,
      "loss": 2.6589,
      "step": 620
    },
    {
      "epoch": 0.9104046242774566,
      "grad_norm": 1.1098164319992065,
      "learning_rate": 3.028112449799197e-05,
      "loss": 2.6674,
      "step": 630
    },
    {
      "epoch": 0.9248554913294798,
      "grad_norm": 1.0295435190200806,
      "learning_rate": 2.987951807228916e-05,
      "loss": 2.6642,
      "step": 640
    },
    {
      "epoch": 0.9393063583815029,
      "grad_norm": 1.1246305704116821,
      "learning_rate": 2.947791164658635e-05,
      "loss": 2.661,
      "step": 650
    },
    {
      "epoch": 0.953757225433526,
      "grad_norm": 1.2026535272598267,
      "learning_rate": 2.9076305220883538e-05,
      "loss": 2.6114,
      "step": 660
    },
    {
      "epoch": 0.9682080924855492,
      "grad_norm": 1.1663471460342407,
      "learning_rate": 2.8674698795180727e-05,
      "loss": 2.6548,
      "step": 670
    },
    {
      "epoch": 0.9826589595375722,
      "grad_norm": 1.3090256452560425,
      "learning_rate": 2.827309236947791e-05,
      "loss": 2.6253,
      "step": 680
    },
    {
      "epoch": 0.9971098265895953,
      "grad_norm": 1.2640045881271362,
      "learning_rate": 2.78714859437751e-05,
      "loss": 2.7035,
      "step": 690
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.484206438064575,
      "eval_runtime": 177.8843,
      "eval_samples_per_second": 5.644,
      "eval_steps_per_second": 0.708,
      "step": 692
    }
  ],
  "logging_steps": 10,
  "max_steps": 1384,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 362757463474176.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
